{
    "collab_server" : "",
    "contents" : "pacman::p_load(dplyr, pandocfilters, jsonlite,tidyjson, xml2, rvest)\n\ntt %>% jsonlite::fromJSON()\n\nlibrary(rvest)\n\nex <- xml2::read_html(\"http://data-steve.github.io/need-user-feedback-send-programmatically/\")\n\nurl <- \"http://data-steve.github.io/need-user-feedback-send-programmatically/\"\nurl2md <- function(url) {\n  xx   <- xml2::read_html(url)\n  title <- paste0(\"---\\ntitle: \", xml_text(xml_node(xx,\"title\")), \"\\n---\\n\")\n  divs <- xml_nodes(xml_node(xx,\"body\"),\"div\")\n  body_html <- as.character(divs[max(grep(\"<p>\",divs))])\n  md <- system(sprintf(\"echo %s | pandoc -r html  -t markdown\", shQuote(body_html))\n         , intern = TRUE, ignore.stderr = TRUE)\n  c(title, md[!grepl(\"<div|</div>|^\\\\\\\\\",md)])\n}\n\n\ntest2 <-url2md(\"http://data-steve.github.io/need-user-feedback-send-programmatically/\")\nwriteLines(test2,\"~/Desktop/test.md\")\n\n\npndc <- function (url, to_file = FALSE, file = NA){\n  if (!to_file) {\n    system(paste0(\"pandoc -r html  \", url, \" -t markdown\")\n           , intern = TRUE, ignore.stderr = TRUE)\n  }\n  else {\n    if (is.na(file)) stop(message(\"file must not be NA\"))\n    system(paste0(\"pandoc -r  html  \", url, \" -o \", file)\n           , intern = TRUE, ignore.stderr = TRUE)\n  }\n}\n\nhtml_md <- function(urlvec){\n  if(length(urlvec)>1){\n      lapply(1:length(urlvec), function(x){\n        pndc(urlvec[x]\n              , to_file=TRUE\n              , file= file.path(path.expand(\"~/Desktop\"),paste0(\"blogtest/new/test\",x,\".md\") ) )\n            })\n  } else {\n    pndc(urlvec\n         , to_file=TRUE\n         , file= file.path(path.expand(\"~/Desktop\"),paste0(\"blogtest/new/test.md\") ) )\n\n  }\n}\n\n\n\npandoc_to_json <- function(file, from=\"markdown\") {\n  args <- sprintf(\"-f %s -t json %s\", from, file)\n  system2(\"pandoc\", args, stdout=TRUE, stderr=FALSE)\n}\n\n\n\n\n\ntest_filter <- function(x, to=\"html\") {\n  d <- list(list(unMeta=setNames(list(), character())), x)\n  pandoc_from_json(as.character(jsonlite::toJSON(d, auto_unbox=TRUE)), to=to)\n}\n\n\nfile <- \"~/Documents/repos/github_packages/browzr/data/test.md\"\n\n# pandoc -f markdown -t json ~/Documents/repos/github_packages/browzr/data/test.md\ntest <- readLines(file)\n\ntt <- jsonlite::toJSON(test)\n\ntt2 <- pandoc_to_json(file)\ntt2 <- sub(\"S pace\",\"Space\",tt2)\njj <- jsonlite::fromJSON(tt3,  simplifyVector = T)\n\ntt2\n\nas.list(tt2[1])\nstrsplit(tt2[1],\"},\")\n\nwriteLines(paste(tt2,collapse=\"\"), \"~/Documents/repos/github_packages/browzr/data/tt2.md\")\n\n  regexpr(\"S\",tt3)\n\nrmd <- jsonlite::toJSON(\"~/\", auto_unbox=TRUE)\nlapply(rmd, is.block)\n\nvec_url <- \"http://data-steve.github.io/making-ggdumbbell-smarter/\"\nhtml_md(vec_url)\n\nll <- jsonlite::toJSON(vec_url)\n\n\nlapply(ll,print)\n\n\nlength(ll)\nexample_1 <- file.path(system.file(package = \"pandocfilters\"), \"examples\", \"lower_case.md\")\n# the file before transformation\nll <-readLines(example_1)\n\n# read connection\ninput_connection <- textConnection(pandoc_to_json(ll, from=\"markdown\"))\n# write connection\noutput_connection <- textConnection(\"modified_ast\", open=\"w\")\n\n# apply filter\nfilter(caps, input=input_connection, output=output_connection)\n\n# convert altered ast to markdown\npandoc_from_json(modified_ast, to=\"markdown\")\n\n\n\nlapply(ll, pandocfilters::is.block)\n\n# pndc(\"http://data-steve.github.io/making-ggdumbbell-smarter/\"\n#      , to_file=TRUE\n#      , file= file.path(path.expand(\"~/Desktop\"),paste0(\"blogtest/new/test1.md\") ) )\n#\n#\n#\nvec_url <- c(\"http://data-steve.github.io/need-user-feedback-send-programmatically/\"\n             , \"http://www.beardedanalytics.com/correctly-reporting-p-values-in-summary-tables-reported-with-xtable/\"\n             , \"https://brendanrocks.com/htmlwidgets-knitr-jekyll/\"\n             , \"http://www.bytemining.com/2016/02/its-been-a-while/\"\n             , \"http://chrisladroue.com/2014/11/another-take-on-building-a-multi-lingual-shiny-app/\"\n             , \"http://christophergandrud.blogspot.com/2015/05/a-link-between-topicmodels-lda-and.html\"\n             , \"http://citizen-statistician.org/2016/02/02/how-do-readers-perceive-the-results-of-a-data-analysis/\"\n             , \"http://civilstat.com/2016/04/after-5th-semester-of-statistics-phd-program/\")\n\n\n\n\n\n\n\n\n\n\n\n\nhome <- \"~/Desktop/blogtest\"\n\nxx <- lapply(grep(\"test\",dir(home), value = T), function(x) readLines(cl::go(home, x)))\n             'abc(\\n|.)*?efg'\ngrep(\"</div>(\\n|\\\"\\\"|.)*?</div>\",xx[[1]], perl = T )\nsystem(\"awk '/<\\/div>/,/<\\/div>/,/<\\/div>/!d' ~/Desktop/blogtest/test.md\")\nxx[[1]][!sapply(xx[[1]],function(x) grepl(\"<div|</div\",x), USE.NAMES = F)]\n\n\n\n\n\n# scraper for ending\nbody <- xx[[1]]\nhits <- rep(0, length(body))\nhits[grep(\"^\\\\s*</div>\\\\s*$\", body)] <- 1\nhits[grep(\"^\\\\s*$\", body)] <- 2\n\n\n# distinguish different blogging platforms\n# they likely have different conventions\n# for making start, stop, code chunks....\nfind_blogger <- function(x){\n  any(grep(\"generator: blogger\", x))\n}\n\nsapply(xx, find_blogger)\n\nfind_wordpress <- function(x){\n  any(grep(\"generator.*?wordpress\", x, ignore.case = T))\n}\n\nsapply(xx, find_wordpress)\n\nfind_other  <- function(x){\n  !any(grep(\"generator:\", x, ignore.case = T))\n}\n\nsapply(xx, find_other)\n\n\n\n# noticed that most use \"=footer\" to make end of content\nsapply(xx, function(x)  min(grep(\"footer\",x)) )\n\n\nsapply(xx, function(x) {\n  y<-min(grep(\"footer\",xx[[8]]), na.rm = T)\n  x[(y-20):(y+20)]\n  })\n\ngregexpr(\"12121\", paste(hits, collapse=\"\"))\n\nlocs <- lapply(gregexpr(\"12121\", paste(hits, collapse=\"\"))[[1]], function(x) x:c(x + 4))\n\n",
    "created" : 1463618823032.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2023401059",
    "id" : "B321D1EE",
    "lastKnownWriteTime" : 1463714136,
    "last_content_update" : 0,
    "path" : "~/Documents/repos/github_packages/browzr/scripts/scraper2.R",
    "project_path" : "scripts/scraper2.R",
    "properties" : {
        "chunk_rendered_width" : "650"
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}