{
    "collab_server" : "",
    "contents" : "pacman::p_load(xml2, rvest, dplyr, jsonlite)\n\n\nasc <- function(xx) as.character(xx)\n\n\ntest_for_div <- function(tree) {\n  out <- capture.output(html_structure(tree[[1]]))[1]\n  if (grepl(\"div\",out)){\n    TRUE\n  } else {\n    return(gsub(\"<|>\",\"\",out))\n  }\n}\n\nclasses <-c(\"entry-content\", \"post-content\", \"post\")\n\n\nurl_num <-grep(\"blogspot\",vec_url)\n\nurl2Rmd <- function(url) {\n  xx    <- xml2::read_html(vec_url[url_num])\n  title <- xml2::xml_text(rvest::xml_node(xx,\"title\"))\n  # xml2::xml_attr(rvest::xml_nodes(xx,\"meta\"), \"generator\")\n  test <- rvest::xml_nodes(xx,\"body\")\n\n  # xml2::xml_parent(rvest::xml_nodes(rvest::xml_nodes(xx,\"body\"), \"p\"))\n  # asc(xml_find_all(test,\"//div/p\"))\n  # xml2::xml_parent()\n  content_post <-names(which.max(sapply(classes,function(z) regexpr(z,asc(xx)))))\n  xml_find_first(xx,xpath=\".//div[contains(@class, 'entry-content')]\")\n  xml_nodes(xx,xpath=\"*[contains(@class, 'gist-meta')]\")\n  body  <- xml_parent(xml_parent(xml_nodes(xx, paste(\"div\",content_post,sep=\".\"))))\n  xml_find_first(xx, xpath=\"*[contains(@id,'gist')]\")\n  # walk up tree till hit a div tag\n  # while (!isTRUE(test_for_div(test))) {\n  #   test <- xml2::xml_parent(rvest::xml_nodes(test, test_for_div(test)))\n  # }\n  # keep only divs for entry or post class (no comments)\n\n  #gist\n  xml_attr(xml_nodes(xml_find_first(xx,xpath=\".//div[contains(@class, 'entry-content')]\"),\"script\"),\"src\")\n  \"https://gist.github.com/christophergandrud/00e7451c16439421b24a.js\"\n  xml_attr(xml_nodes(xml_find_first(xx,xpath=\".//div[contains(@class, 'file-actions')]\"),\"a\"),\"href\")\n  /christophergandrud/00e7451c16439421b24a/raw/3d114fefa4845060fb015e7644b839beddb03701/topicmodels_json_ldavis.R\n  https://gist.githubusercontent.com/\n\n\n\n  xml2::xml_contents(body)\n  if (grepl(\"<pre>\", asc(body))){\n\n  }\n  if (grepl('gist-file', asc(body))\n  v1 <- xml2::xml_text(body[grepl(\"<pre>\", asc(body))])\n  if (any(grepl(\"(\\\\d\\n)+\", v1))) {\n    v1[grepl(\"(\\\\d+\\n)+\", v1)] <- gsub(\"^.+?(\\\\d+\\n)+(\\\\s+|\\n+)*\", \"\", v1[grepl(\"(\\\\d+\\n)+\", v1)])\n  }\n  xml2::(v1)\n  xml2::read_xml(asc(lapply(v1, htmltools::code)[[1]]))\n  body[grepl(\"<pre>\", asc(body))]  <- )\n\n  # rvest::xml_nodes(bd,\"div.entry-content\")\n\n  # generator <- get_generator(xx)\n  # get_body(xx)\n\n\n}\n\n\n\n\nurl2Rmd <- function(url) {\n  xx   <- xml2::read_html(url)\n  title <- xml2::xml_text(rvest::xml_node(xx,\"title\"))\n  generator <- get_generator(xx)\n  get_body(xx)\n\n}\nfind/clean body content\nfind/clean code chunks\n\n\nbody_html <- shiny::tags$body(body)\nmd <- system(sprintf(\"echo %s | pandoc -r html  -t markdown\", shQuote(body_html))\n             , intern = TRUE, ignore.stderr = TRUE)\nbody <- gsub(\"```[ ]{0,1}\\\\{.*?\\\\}\",\"```\\\\{r\\\\}\",md[!grepl(\"<div|</div>|^\\\\\\\\\",md)])\nyml <- paste('---'\n             , 'title: \"R Notebook\"'\n             , 'output: html_notebook'\n             , '---'\n             , '\\n\\n', sep=\"\\n\")\nfilename <- paste0(paste(strsplit(tolower(title),\"\\\\s+\")[[1]],collapse=\"-\"),\".Rmd\")\nplace <- file.path(tempdir(),filename)\nwriteLines(c(yml,paste0(\"# \", title), body)  ,  place)\nfile.edit(place)\n}\n\nget_generator <- function(xx){\n  x <- as.character(xx)\n  if (any(grepl(\"wp-\",x)) ) {\n    \"wordpress\"\n  } else if (any(grepl(\"blogger[.]\",x))) {\n    \"blogger\"\n  } else {\n    \"jekyll\"\n  }\n}\n\nget_body <- function(xx) {\n  bd <- rvest::xml_nodes(xml2::read_html(xx),\"body\")\n  if (grepl('entry-content',bd)) {\n    rvest::xml_nodes(bd,\"div.entry-content\")\n  } else {\n    rvest::xml_nodes(bd,\"div.post\")\n  }\n}\n\nx5<-get_body(x5)\n\nget_code <- function(xx){\n  browser()\n  ll <- xml2::xml_contents(xx)\n  has <- grepl(\"div\",ll)\n  if (any(has)){\n    ll[has][[1]] <- code_converter(ll[has])\n    ll\n  } else {\n    bd_div\n  }\n}\n\ncode_converter <- function(ll){\n  if (any(grepl('class=\"crayon-plain-wrap\"',ll))) {\n    htmltools::code(html_text(xml_nodes(ll, \"div.crayon-plain-wrap\")))\n  } else if (grepl('class=\"code\"',ll)) {\n    htmltools::code(html_text(xml_nodes(ll, \"td.code\")))\n  } else {\n    ll\n  }\n}\n\nget_code(x4)\n\n\n\n\n\n\nread_text <- function(url,flnm){\n  d<-get_body(url)\n  place <- file.path(tempdir(),paste0(flnm,\".md\"))\n  writeLines(as.character(d),  place)\n  file.edit(place)\n}\n\nread_text(u3,\"x3\")\n\n\n\ngrep('class=\"code\"',as.character(x2))\ngrep('class=\"code\"',x2)\n\n\nlocs <- grepl(\".my_syntax_box\",divs)\nif (any(locs)) {\n  to_cl <- writeLines(as.character(divs[locs][5]),\"~/Desktop/test44.md\")\n  as.character(to_cl)\n} else {\n  divs\n}\n\n}\n}\n\n\n\n\n#####\n\nurm <- function(urls){\n  rvest::xml_node(xml2::read_html(urls),\"body\")\n}\n\nu1 <- \"http://chrisladroue.com/2014/11/another-take-on-building-a-multi-lingual-shiny-app/\"\nx1   <- urm(u1)\n\nu2 <- \"http://data-steve.github.io/making-ggdumbbell-smarter/\"\nx2   <- urm(u2)\n\nu3 <- \"http://www.beardedanalytics.com/correctly-reporting-p-values-in-summary-tables-reported-with-xtable/\"\nx3   <- urm(u3)\n\nu4 <- \"http://www.bytemining.com/2016/02/its-been-a-while/\"\nx4   <- urm(u4)\n\nx5 <- \"http://rogiersbart.blogspot.com/2016/04/a-workflow-for-publishing-rstudio.html\"\n\nhttp://brendanrocks.com/htmlwidgets-knitr-jekyll/\n\n  as.character(xml2::read_html(\"http://brendanrocks.com/htmlwidgets-knitr-jekyll/\"))\n\n\n# strsplit(tolower(xml2::xml_text(rvest::xml_node(xx,\"title\"))),\"\\\\s+\")[[1]][1]\n# divs <- rvest::xml_nodes(rvest::xml_node(xx,\"body\"),\"div.post\")\n# writeLines(x,\"~/Desktop/test45.md\")\n# file.edit(\"~/Desktop/test45.md\")\n\n# http://rogiersbart.blogspot.com/2016/04/a-workflow-for-publishing-rstudio.html\n\nurl2Rmd(urlz)\n\n\n\ndiv.my_syntax_box  -> <td class=\"code\">\n  div.crayon-plain-wrap\n\n\nwriteLines(as.character(x3),\"~/Desktop/test43.md\")\nfile.edit(\"~/Desktop/test43.md\")\n\n\n\n\n\nload_checker <- function(md){\n  loaders <- c(\"library\\\\(\",\"require\\\\(\",\"p_load\\\\(\")\n  the_l <- loaders[sapply(loaders,function(x) any(grepl(x,md)))]\n  if (length(the_l)==0){\n    return(\"library\")\n  } else {\n    return(the_l)\n  }\n}\nloader <- load_checker(test2)\n\nfind_\n\n\nvec_url <- c(\"http://data-steve.github.io/need-user-feedback-send-programmatically/\"\n             , \"http://www.beardedanalytics.com/correctly-reporting-p-values-in-summary-tables-reported-with-xtable/\"\n             , \"https://brendanrocks.com/htmlwidgets-knitr-jekyll/\"\n             , \"http://www.bytemining.com/2016/02/its-been-a-while/\"\n             , \"http://chrisladroue.com/2014/11/another-take-on-building-a-multi-lingual-shiny-app/\"\n             , \"http://christophergandrud.blogspot.com/2015/05/a-link-between-topicmodels-lda-and.html\"\n             , \"http://citizen-statistician.org/2016/02/02/how-do-readers-perceive-the-results-of-a-data-analysis/\"\n             , \"http://civilstat.com/2016/04/after-5th-semester-of-statistics-phd-program/\")\n\ntest2 <-url2md(\"http://data-steve.github.io/need-user-feedback-send-programmatically/\")\n\ngrep(\"```\",test2)\n\nzz <-\n\n\n\n\n\n\n\n  src    <- strsplit(paste(zz,collapse=\"\\n\"),\"```\")[[1]]\nsrc2 <- lapply(src, function(x) paste0(strsplit(x, \"\\n\")[[1]],\"\\n\"))\ncell_type <- ifelse(as.logical(rep(c(0,1),length(src))[1:length(src)]), \"code\",\"markdown\")\n\ncontents <- data.frame(cell_type = cell_type, stringsAsFactors = F)\ncontents$source <- c(NA,NA,NA)\ncontents$outputs <- \"[]\"\n\ncontents$source <- unlist(lapply(1:length(contents$cell_type), function(i) {\n  paste(shQuote(src2[[i]]),collapse = \",\")\n}))\n\n\npaste(toJSON(conte))\n\njptr <- list()\njptr$cells <- toJSON(contents)\njptr$metadata <- jj\nlist()\njsonlite::validate(jsonlite::toJSON(contents))\nwriteLines(jsonlite::prettify(jsonlite::toJSON(contents)),\"~/Desktop/test2.ipynb\")\n\n\njj <- fromJSON(readLines(cl::go(home, \"data/jupyter-metadata.txt\")))\n\ncells <- toJSON(contents)\n\ntest <-list(toJSON(contents),toJSON(jj))\n\nprettify(test)\n\nz2[]\npndc <- function (url, to_file = FALSE, file = NA){\n  if (!to_file) {\n    system(paste0(\"pandoc -r html  \", url, \" -t markdown\")\n           , intern = TRUE, ignore.stderr = TRUE)\n  }\n  else {\n    if (is.na(file)) stop(message(\"file must not be NA\"))\n    system(paste0(\"pandoc -r  html  \", url, \" -o \", file)\n           , intern = TRUE, ignore.stderr = TRUE)\n  }\n}\n\nhtml_md <- function(urlvec){\n  if(length(urlvec)>1){\n    lapply(1:length(urlvec), function(x){\n      pndc(urlvec[x]\n           , to_file=TRUE\n           , file= file.path(path.expand(\"~/Desktop\"),paste0(\"blogtest/new/test\",x,\".md\") ) )\n    })\n  } else {\n    pndc(urlvec\n         , to_file=TRUE\n         , file= file.path(path.expand(\"~/Desktop\"),paste0(\"blogtest/new/test.md\") ) )\n\n  }\n}\n",
    "created" : 1464989130979.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3741190367",
    "id" : "9C21B482",
    "lastKnownWriteTime" : 1465009828,
    "last_content_update" : 1465009828351,
    "path" : "~/Documents/repos/github_packages/browzr/scripts/url2Rmd2.R",
    "project_path" : "scripts/url2Rmd2.R",
    "properties" : {
        "chunk_rendered_width" : "650",
        "tempName" : "Untitled1"
    },
    "relative_order" : 20,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}